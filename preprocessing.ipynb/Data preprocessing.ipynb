{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df357da7",
   "metadata": {},
   "source": [
    "`Student name`: Mitchelle Moraa\n",
    "\n",
    "`Task`: Data Preprocessing-One hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6cc8d5",
   "metadata": {},
   "source": [
    "__import re__\n",
    "\n",
    "* Used for string cleaning and normalization.\n",
    "\n",
    "\n",
    "__import csv__\n",
    "\n",
    "* Allows reading and writing CSV files in plain Python.\n",
    "* Save cleaned transactions row by row or read CSVs without pandas.\n",
    "\n",
    "__import os__\n",
    "\n",
    "* Provides tools to interact with the filesystem.\n",
    "\n",
    "_Used for_\n",
    "\n",
    "* Creating directories (os.makedirs)\n",
    "\n",
    "* Joining file paths (os.path.join)\n",
    "\n",
    "* Checking if directories exist\n",
    "\n",
    "__from collections import Counter, defaultdict__\n",
    "\n",
    "* Counts frequency of items in a list or iterable.\n",
    "\n",
    "__defaultdict:__\n",
    "\n",
    "* Like a normal dictionary but provides default values automatically for missing keys.\n",
    "\n",
    "__from typing import List, Tuple, Dict, Any, Optional__\n",
    "\n",
    "* Provides type hints to make code more readable and help with debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "07a0182f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re                      \n",
    "import csv                      \n",
    "import os                      \n",
    "from collections import Counter, defaultdict\n",
    "from typing import List, Tuple, Dict, Any, Optional\n",
    "\n",
    "import pandas as pd           \n",
    "from mlxtend.preprocessing import TransactionEncoder  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544638ee",
   "metadata": {},
   "source": [
    "This block sets all paths, parameters, and directories needed for the preprocessing pipeline so that your code can read the \n",
    "\n",
    "raw CSV, clean it, and save outputs safely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fd7cc234",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPORT_DIR = \"preprocessed_outputs\" \n",
    "LOAD_PATH = \"C:/Users/USER/Downloads/Data Warehousing/supermarket_transactions.csv\"                 \n",
    "MIN_ITEMS_PER_TX = 2               \n",
    "MAX_ITEMS_PER_TX = 7                \n",
    "OHE_CSV_NAME = \"one_hot_transactions.csv\"\n",
    "CLEAN_CSV_NAME = \"clean_transactions.csv\"\n",
    "SUMMARY_CSV_NAME = \"preprocessing_summary.csv\"\n",
    "\n",
    "os.makedirs(EXPORT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cb51d5",
   "metadata": {},
   "source": [
    "_str(item)_  : ensures the input is a string (handles None or numbers).\n",
    "\n",
    "_.strip()_  : removes spaces at the beginning or end (\" Milk \" → \"Milk\").\n",
    "\n",
    "_.lower()_ :  everything to lowercase (\"Milk\" → \"milk\").\n",
    "\n",
    "_re.sub(pattern, replacement, string)_ : replaces all characters matching the pattern with a space.\n",
    "\n",
    "_\\s+_ : matches one or more whitespace characters\n",
    "\n",
    "Replaces them with a single space\n",
    "\n",
    "_s.replace_ : \"&\" to \" and \"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "869409bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_item_name(item: str) -> str:\n",
    "    s = str(item).strip().lower()\n",
    "    s = re.sub(r\"[\\.\\-_/\\\\\\(\\)]\", \" \", s)  # remove punctuation\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    s = s.replace(\"&\", \" and \")\n",
    "    return s.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adfe736",
   "metadata": {},
   "source": [
    "__Example use__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f49d3a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: ['Fish', 'Salt', 'Sugar', 'Cereal', 'Soap', 'Toothpaste']\n",
      "Cleaned : ['fish', 'salt', 'sugar', 'cereal', 'soap', 'toothpaste']\n",
      "\n",
      "Original: ['Shampoo', 'Oranges', 'Potatoes']\n",
      "Cleaned : ['shampoo', 'oranges', 'potatoes']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transactions = [\n",
    "    [\"Fish\", \"Salt\", \"Sugar\", \"Cereal\", \"Soap\", \"Toothpaste\"],\n",
    "    [\"Shampoo\", \"Oranges\", \"Potatoes\"]\n",
    "]\n",
    "for tx in transactions:\n",
    "    cleaned_tx = [normalize_item_name(item) for item in tx]\n",
    "    print(f\"Original: {tx}\")\n",
    "    print(f\"Cleaned : {cleaned_tx}\")\n",
    "    print(\"\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fce2b2",
   "metadata": {},
   "source": [
    "This ensures no empty items or None values remain in a single transaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "238f868a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_transaction(tx: List[str]) -> List[str]:\n",
    "    cleaned = [normalize_item_name(it) for it in tx if it and normalize_item_name(it) != \"\"]\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82952c9",
   "metadata": {},
   "source": [
    "_min items_ / _max items_: filters out transactions that are beyond the 2 or 7 boundary\n",
    "\n",
    "transactions outside the allowed item range are dropped.\n",
    "\n",
    "only transactions with an acceptable number of items are kept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "67096fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_transactions(transactions: List[List[str]],\n",
    "                       min_items: int = MIN_ITEMS_PER_TX,\n",
    "                       max_items: int = MAX_ITEMS_PER_TX) -> List[List[str]]:\n",
    "    cleaned_all = []\n",
    "    for tx in transactions:\n",
    "        cleaned_tx = clean_transaction(tx)\n",
    "        if len(cleaned_tx) < min_items:\n",
    "            continue\n",
    "        if len(cleaned_tx) > max_items:\n",
    "            continue\n",
    "        cleaned_all.append(cleaned_tx)\n",
    "    return cleaned_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636a30dc",
   "metadata": {},
   "source": [
    "__Sorts the items in alphabetical order:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "167128ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_items_in_transactions(transactions: List[List[str]]) -> List[List[str]]:\n",
    "    return [sorted(tx) for tx in transactions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "25109f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bread', 'Eggs', 'Milk']\n",
      "['Juice', 'Soap', 'Tea']\n",
      "['Coffee', 'Onions', 'Potatoes']\n"
     ]
    }
   ],
   "source": [
    "transactions = [\n",
    "    [\"Milk\", \"Bread\", \"Eggs\"],\n",
    "    [\"Juice\", \"Soap\", \"Tea\"],\n",
    "    [\"Potatoes\", \"Coffee\", \"Onions\"]\n",
    "]\n",
    "\n",
    "sorted_tx = sort_items_in_transactions(transactions)\n",
    "for tx in sorted_tx:\n",
    "    print(tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4b1eb6de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('<M8[ns]')"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "df['Date'].dtype\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe69f5b",
   "metadata": {},
   "source": [
    "`TransactionEncoder()` comes from mlxtend.\n",
    "\n",
    "It converts transactions into a boolean array  for each unique item.\n",
    "\n",
    "`fit(transactions)` finds all unique items in your dataset.\n",
    "\n",
    "`transform(transactions)` creates a 2D array where:\n",
    "\n",
    "Rows = transactions\n",
    "\n",
    "Columns = unique items\n",
    "\n",
    "Value = True if the item exists in that transaction, else False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "2c21dc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode_transactions(transactions: List[List[str]]) -> pd.DataFrame:\n",
    "    \"\"\"One-hot encode transactions for Apriori.\"\"\"\n",
    "    te = TransactionEncoder()\n",
    "    te_ary = te.fit(transactions).transform(transactions)\n",
    "    df = pd.DataFrame(te_ary, columns=te.columns_).astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c798fb25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   bread  coffee  eggs  juice  milk  onions  potatoes  soap\n",
      "0      1       0     1      0     1       0         0     0\n",
      "1      0       0     0      1     0       0         0     1\n",
      "2      0       1     0      0     0       1         1     0\n"
     ]
    }
   ],
   "source": [
    "transactions = [\n",
    "    ['milk', 'bread', 'eggs'],\n",
    "    ['juice', 'soap'],\n",
    "    ['potatoes', 'coffee', 'onions']\n",
    "]\n",
    "ohe_df = one_hot_encode_transactions(transactions)\n",
    "print(ohe_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84629399",
   "metadata": {},
   "source": [
    "__1 → the transaction contains that item.__\n",
    "\n",
    "__0 → the transaction does not contain that item__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "202031a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_transactions': 3,\n",
       " 'avg_tx_length': 2.6666666666666665,\n",
       " 'min_tx_length': 2,\n",
       " 'max_tx_length': 3,\n",
       " 'num_unique_items': 8,\n",
       " 'unique_items_sample': ['bread',\n",
       "  'coffee',\n",
       "  'eggs',\n",
       "  'juice',\n",
       "  'milk',\n",
       "  'onions',\n",
       "  'potatoes',\n",
       "  'soap'],\n",
       " 'top_20_items': [('milk', 1),\n",
       "  ('bread', 1),\n",
       "  ('eggs', 1),\n",
       "  ('juice', 1),\n",
       "  ('soap', 1),\n",
       "  ('potatoes', 1),\n",
       "  ('coffee', 1),\n",
       "  ('onions', 1)],\n",
       " 'item_counts': {'milk': 1,\n",
       "  'bread': 1,\n",
       "  'eggs': 1,\n",
       "  'juice': 1,\n",
       "  'soap': 1,\n",
       "  'potatoes': 1,\n",
       "  'coffee': 1,\n",
       "  'onions': 1}}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_data_quality(transactions: List[List[str]]) -> Dict[str, Any]:\n",
    "    n = len(transactions)\n",
    "    lengths = [len(tx) for tx in transactions]\n",
    "    avg_len = sum(lengths)/n if n else 0\n",
    "    min_len = min(lengths) if lengths else 0\n",
    "    max_len = max(lengths) if lengths else 0\n",
    "    flat_items = [item for tx in transactions for item in tx]\n",
    "    unique_items = sorted(set(flat_items))\n",
    "    item_counts = Counter(flat_items)\n",
    "    summary = {\n",
    "        \"num_transactions\": n,\n",
    "        \"avg_tx_length\": avg_len,\n",
    "        \"min_tx_length\": min_len,\n",
    "        \"max_tx_length\": max_len,\n",
    "        \"num_unique_items\": len(unique_items),\n",
    "        \"unique_items_sample\": unique_items[:30],\n",
    "        \"top_20_items\": item_counts.most_common(20),\n",
    "        \"item_counts\": dict(item_counts)\n",
    "    }\n",
    "    return summary\n",
    "summary_stats = check_data_quality(transactions)\n",
    "summary_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e3703039",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_clean_transactions_csv(df, export_dir, filename=\"full_cleaned_dataset.csv\"):\n",
    "    os.makedirs(export_dir, exist_ok=True)\n",
    "    path = os.path.join(export_dir, filename)\n",
    "    df.to_csv(path, index=False)\n",
    "    print(f\"Cleaned transactions CSV saved to: {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "6c42aa6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_ohe_csv(ohe_df: pd.DataFrame, export_dir: str, filename: str):\n",
    "    os.makedirs(export_dir, exist_ok=True)\n",
    "    path = os.path.join(export_dir, filename)\n",
    "    ohe_df.to_csv(path, index=False)\n",
    "    print(f\"One-hot encoded CSV saved to: {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "8a415773",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_summary_csv(summary: Dict[str, Any], export_dir: str, filename: str):\n",
    "    os.makedirs(export_dir, exist_ok=True)\n",
    "    path = os.path.join(export_dir, filename)\n",
    "    df_summary.to_csv(path, index=False)\n",
    "    print(f\"Summary CSV saved to: {path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "923ebb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat = {\n",
    "        \"num_transactions\": summary_stats.get(\"num_transactions\", 0),\n",
    "        \"avg_tx_length\": summary_stats.get(\"avg_tx_length\", 0),\n",
    "        \"min_tx_length\": summary_stats.get(\"min_tx_length\", 0),\n",
    "        \"max_tx_length\": summary_stats.get(\"max_tx_length\", 0),\n",
    "        \"num_unique_items\": summary_stats.get(\"num_unique_items\", 0)\n",
    "    }\n",
    "df_flat = pd.DataFrame([flat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "0555541f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_transactions</th>\n",
       "      <th>avg_tx_length</th>\n",
       "      <th>min_tx_length</th>\n",
       "      <th>max_tx_length</th>\n",
       "      <th>num_unique_items</th>\n",
       "      <th>item</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>milk</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bread</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>eggs</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>juice</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>soap</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>potatoes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>coffee</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>onions</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_transactions  avg_tx_length  min_tx_length  max_tx_length  \\\n",
       "0               3.0       2.666667            2.0            3.0   \n",
       "1               NaN            NaN            NaN            NaN   \n",
       "2               NaN            NaN            NaN            NaN   \n",
       "3               NaN            NaN            NaN            NaN   \n",
       "4               NaN            NaN            NaN            NaN   \n",
       "5               NaN            NaN            NaN            NaN   \n",
       "6               NaN            NaN            NaN            NaN   \n",
       "7               NaN            NaN            NaN            NaN   \n",
       "\n",
       "   num_unique_items      item  count  \n",
       "0               8.0      milk      1  \n",
       "1               NaN     bread      1  \n",
       "2               NaN      eggs      1  \n",
       "3               NaN     juice      1  \n",
       "4               NaN      soap      1  \n",
       "5               NaN  potatoes      1  \n",
       "6               NaN    coffee      1  \n",
       "7               NaN    onions      1  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_flat = pd.DataFrame([flat])\n",
    "top_items = summary_stats.get(\"top_20_items\", [])\n",
    "df_top = pd.DataFrame(top_items, columns=[\"item\", \"count\"])\n",
    "df_summary = pd.concat([df_flat, df_top], axis=1)\n",
    "df_summary.to_csv(\"path\", index=False)\n",
    "print(f\"path\")\n",
    "df_summary "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3f0d3a",
   "metadata": {},
   "source": [
    "`num_transactions`\tTotal number of transactions in your dataset. Only the first row has this value because the code repeated the summary stats for every top item. Here, 5000 transactions.\n",
    "\n",
    "`avg_tx_length`\tAverage number of items per transaction. Here 4.4904 items on average.\n",
    "\n",
    "`min_tx_length`\tSmallest transaction length (number of items). Here 2.0 items. \n",
    "`max_tx_length`\tLargest transaction length. Here 7.0 items. \n",
    "\n",
    "`num_unique_items`\tTotal number of unique items across all transactions. Here 30. \n",
    "\n",
    "`item`\t_Name of the item_. This comes from the top 20 most frequent items list. Repeats down the rows.\n",
    "count\tHow many times that item appears across all transactions. Example: \"soap\" occurs 788 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4db49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_pipeline(LOAD_PATH: Optional[str] = None):\n",
    "    df_original = pd.read_csv(LOAD_PATH)\n",
    "    \n",
    "    if \"Date\" in df_original.columns:\n",
    "        df_original[\"Date\"] = pd.to_datetime(df_original[\"Date\"], errors=\"coerce\")\n",
    "    df_original[\"Original_Items\"] = df_original.iloc[:, -1].apply(lambda x: str(x).split(\",\"))\n",
    "    df_original[\"Cleaned_Items\"] = df_original[\"Original_Items\"].apply(clean_transaction)\n",
    "    df_original[\"Sorted_Items\"] = df_original[\"Cleaned_Items\"].apply(sorted)\n",
    "    df_original[\"cleaned_items\"] = df_original[\"Sorted_Items\"].apply(lambda tx: \"; \".join(tx))\n",
    "    sorted_tx = df_original[\"Sorted_Items\"].tolist()\n",
    "    ohe_df = one_hot_encode_transactions(sorted_tx)\n",
    "    summary_stats = check_data_quality(sorted_tx)\n",
    "\n",
    "    return df_original, ohe_df, summary_stats\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b35d55a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned transactions CSV saved to: preprocessed_outputs\\full_cleaned_dataset.csv\n",
      "One-hot encoded CSV saved to: preprocessed_outputs\\one_hot_transactions.csv\n",
      "Summary CSV saved to: preprocessed_outputs\\preprocessing_summary.csv\n"
     ]
    }
   ],
   "source": [
    "df_original_with_clean, ohe_df, summary_stats = preprocess_pipeline(LOAD_PATH)\n",
    "\n",
    "save_clean_transactions_csv(df_original_with_clean, EXPORT_DIR)\n",
    "save_ohe_csv(ohe_df, EXPORT_DIR, OHE_CSV_NAME)\n",
    "save_summary_csv(summary_stats, EXPORT_DIR, SUMMARY_CSV_NAME)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "5ac6c3ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of transactions: 5000\n",
      "Unique items (sample): ['apples', 'bananas', 'beef', 'bread', 'butter', 'carrots', 'cereal', 'cheese', 'chicken', 'coffee']\n",
      "Top 10 items (item, count):\n",
      "[('soap', 788), ('bread', 787), ('salt', 786), ('toothpaste', 780), ('fish', 778), ('bananas', 776), ('shampoo', 773), ('tomatoes', 767), ('coffee', 762), ('flour', 761)]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    df_cleaned, df_ohe, summary_stats = preprocess_pipeline(LOAD_PATH)\n",
    "    \n",
    "    print(f\"Number of transactions: {summary_stats['num_transactions']}\")\n",
    "    print(f\"Unique items (sample): {summary_stats['unique_items_sample'][:10]}\")\n",
    "    print(\"Top 10 items (item, count):\")\n",
    "    print(summary_stats[\"top_20_items\"][:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
