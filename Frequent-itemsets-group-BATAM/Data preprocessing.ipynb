{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f6cc8d5",
   "metadata": {},
   "source": [
    "__import re__\n",
    "\n",
    "* Used for string cleaning and normalization.\n",
    "\n",
    "\n",
    "__import csv__\n",
    "\n",
    "* Allows reading and writing CSV files in plain Python.\n",
    "* Save cleaned transactions row by row or read CSVs without pandas.\n",
    "\n",
    "__import os__\n",
    "\n",
    "* Provides tools to interact with the filesystem.\n",
    "\n",
    "_Used for_\n",
    "\n",
    "* Creating directories (os.makedirs)\n",
    "\n",
    "* Joining file paths (os.path.join)\n",
    "\n",
    "* Checking if directories exist\n",
    "\n",
    "__from collections import Counter, defaultdict__\n",
    "\n",
    "* Counts frequency of items in a list or iterable.\n",
    "\n",
    "__defaultdict:__\n",
    "\n",
    "* Like a normal dictionary but provides default values automatically for missing keys.\n",
    "\n",
    "__from typing import List, Tuple, Dict, Any, Optional__\n",
    "\n",
    "* Provides type hints to make code more readable and help with debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "07a0182f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re                      \n",
    "import csv                      \n",
    "import os                      \n",
    "from collections import Counter, defaultdict\n",
    "from typing import List, Tuple, Dict, Any, Optional\n",
    "\n",
    "import pandas as pd           \n",
    "from mlxtend.preprocessing import TransactionEncoder  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544638ee",
   "metadata": {},
   "source": [
    "This block sets all paths, parameters, and directories needed for the preprocessing pipeline so that your code can read the \n",
    "\n",
    "raw CSV, clean it, and save outputs safely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "fd7cc234",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPORT_DIR = \"preprocessed_outputs\"\n",
    "# Use the local CSV in the repository by default. Change this to an absolute path if needed.\n",
    "LOAD_PATH = \"supermarket_transactions.csv\"\n",
    "MIN_ITEMS_PER_TX = 2\n",
    "MAX_ITEMS_PER_TX = 7\n",
    "OHE_CSV_NAME = \"one_hot_transactions.csv\"\n",
    "CLEAN_CSV_NAME = \"clean_transactions.csv\"\n",
    "SUMMARY_CSV_NAME = \"preprocessing_summary.csv\"\n",
    "\n",
    "os.makedirs(EXPORT_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cb51d5",
   "metadata": {},
   "source": [
    "_str(item)_  : ensures the input is a string (handles None or numbers).\n",
    "\n",
    "_.strip()_  : removes spaces at the beginning or end (\" Milk \" → \"Milk\").\n",
    "\n",
    "_.lower()_ :  everything to lowercase (\"Milk\" → \"milk\").\n",
    "\n",
    "_re.sub(pattern, replacement, string)_ : replaces all characters matching the pattern with a space.\n",
    "\n",
    "_\\s+_ : matches one or more whitespace characters\n",
    "\n",
    "Replaces them with a single space\n",
    "\n",
    "_s.replace_ : \"&\" to \" and \"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "869409bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_item_name(item: str) -> str:\n",
    "    s = str(item).strip().lower()\n",
    "    s = re.sub(r\"[\\.\\-_/\\\\\\(\\)]\", \" \", s)  # remove punctuation\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    s = s.replace(\"&\", \" and \")\n",
    "    return s.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adfe736",
   "metadata": {},
   "source": [
    "__Example use__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "f49d3a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: ['Fish', 'Salt', 'Sugar', 'Cereal', 'Soap', 'Toothpaste']\n",
      "Cleaned : ['fish', 'salt', 'sugar', 'cereal', 'soap', 'toothpaste']\n",
      "\n",
      "Original: ['Shampoo', 'Oranges', 'Potatoes']\n",
      "Cleaned : ['shampoo', 'oranges', 'potatoes']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transactions = [\n",
    "    [\"Fish\", \"Salt\", \"Sugar\", \"Cereal\", \"Soap\", \"Toothpaste\"],\n",
    "    [\"Shampoo\", \"Oranges\", \"Potatoes\"]\n",
    "]\n",
    "for tx in transactions:\n",
    "    cleaned_tx = [normalize_item_name(item) for item in tx]\n",
    "    print(f\"Original: {tx}\")\n",
    "    print(f\"Cleaned : {cleaned_tx}\")\n",
    "    print(\"\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fce2b2",
   "metadata": {},
   "source": [
    "This ensures no empty items or None values remain in a single transaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "238f868a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_transaction(tx: List[str]) -> List[str]:\n",
    "    cleaned = [normalize_item_name(it) for it in tx if it and normalize_item_name(it) != \"\"]\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82952c9",
   "metadata": {},
   "source": [
    "_min items_ / _max items_: filters out transactions that are beyond the 2 or 7 boundary\n",
    "\n",
    "transactions outside the allowed item range are dropped.\n",
    "\n",
    "only transactions with an acceptable number of items are kept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "67096fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_transactions(transactions: List[List[str]],\n",
    "                       min_items: int = MIN_ITEMS_PER_TX,\n",
    "                       max_items: int = MAX_ITEMS_PER_TX) -> List[List[str]]:\n",
    "    cleaned_all = []\n",
    "    for tx in transactions:\n",
    "        cleaned_tx = clean_transaction(tx)\n",
    "        if len(cleaned_tx) < min_items:\n",
    "            continue\n",
    "        if len(cleaned_tx) > max_items:\n",
    "            continue\n",
    "        cleaned_all.append(cleaned_tx)\n",
    "    return cleaned_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636a30dc",
   "metadata": {},
   "source": [
    "__Sorts the items in alphabetical order:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "167128ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_items_in_transactions(transactions: List[List[str]]) -> List[List[str]]:\n",
    "    return [sorted(tx) for tx in transactions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "25109f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bread', 'Eggs', 'Milk']\n",
      "['Juice', 'Soap', 'Tea']\n",
      "['Coffee', 'Onions', 'Potatoes']\n"
     ]
    }
   ],
   "source": [
    "transactions = [\n",
    "    [\"Milk\", \"Bread\", \"Eggs\"],\n",
    "    [\"Juice\", \"Soap\", \"Tea\"],\n",
    "    [\"Potatoes\", \"Coffee\", \"Onions\"]\n",
    "]\n",
    "\n",
    "sorted_tx = sort_items_in_transactions(transactions)\n",
    "for tx in sorted_tx:\n",
    "    print(tx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe69f5b",
   "metadata": {},
   "source": [
    "`TransactionEncoder()` comes from mlxtend.\n",
    "\n",
    "It converts transactions into a boolean array  for each unique item.\n",
    "\n",
    "`fit(transactions)` finds all unique items in your dataset.\n",
    "\n",
    "`transform(transactions)` creates a 2D array where:\n",
    "\n",
    "Rows = transactions\n",
    "\n",
    "Columns = unique items\n",
    "\n",
    "Value = True if the item exists in that transaction, else False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "2c21dc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode_transactions(transactions: List[List[str]]) -> pd.DataFrame:\n",
    "    \"\"\"One-hot encode transactions for Apriori.\"\"\"\n",
    "    te = TransactionEncoder()\n",
    "    te_ary = te.fit(transactions).transform(transactions)\n",
    "    df = pd.DataFrame(te_ary, columns=te.columns_).astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "c798fb25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   bread  coffee  eggs  juice  milk  onions  potatoes  soap\n",
      "0      1       0     1      0     1       0         0     0\n",
      "1      0       0     0      1     0       0         0     1\n",
      "2      0       1     0      0     0       1         1     0\n"
     ]
    }
   ],
   "source": [
    "transactions = [\n",
    "    ['milk', 'bread', 'eggs'],\n",
    "    ['juice', 'soap'],\n",
    "    ['potatoes', 'coffee', 'onions']\n",
    "]\n",
    "ohe_df = one_hot_encode_transactions(transactions)\n",
    "print(ohe_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84629399",
   "metadata": {},
   "source": [
    "__1 → the transaction contains that item.__\n",
    "\n",
    "__0 → the transaction does not contain that item__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "202031a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_transactions': 3,\n",
       " 'avg_tx_length': 2.6666666666666665,\n",
       " 'min_tx_length': 2,\n",
       " 'max_tx_length': 3,\n",
       " 'num_unique_items': 8,\n",
       " 'unique_items_sample': ['bread',\n",
       "  'coffee',\n",
       "  'eggs',\n",
       "  'juice',\n",
       "  'milk',\n",
       "  'onions',\n",
       "  'potatoes',\n",
       "  'soap'],\n",
       " 'top_20_items': [('milk', 1),\n",
       "  ('bread', 1),\n",
       "  ('eggs', 1),\n",
       "  ('juice', 1),\n",
       "  ('soap', 1),\n",
       "  ('potatoes', 1),\n",
       "  ('coffee', 1),\n",
       "  ('onions', 1)],\n",
       " 'item_counts': {'milk': 1,\n",
       "  'bread': 1,\n",
       "  'eggs': 1,\n",
       "  'juice': 1,\n",
       "  'soap': 1,\n",
       "  'potatoes': 1,\n",
       "  'coffee': 1,\n",
       "  'onions': 1}}"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_data_quality(transactions: List[List[str]]) -> Dict[str, Any]:\n",
    "    n = len(transactions)\n",
    "    lengths = [len(tx) for tx in transactions]\n",
    "    avg_len = sum(lengths)/n if n else 0\n",
    "    min_len = min(lengths) if lengths else 0\n",
    "    max_len = max(lengths) if lengths else 0\n",
    "    flat_items = [item for tx in transactions for item in tx]\n",
    "    unique_items = sorted(set(flat_items))\n",
    "    item_counts = Counter(flat_items)\n",
    "    summary = {\n",
    "        \"num_transactions\": n,\n",
    "        \"avg_tx_length\": avg_len,\n",
    "        \"min_tx_length\": min_len,\n",
    "        \"max_tx_length\": max_len,\n",
    "        \"num_unique_items\": len(unique_items),\n",
    "        \"unique_items_sample\": unique_items[:30],\n",
    "        \"top_20_items\": item_counts.most_common(20),\n",
    "        \"item_counts\": dict(item_counts)\n",
    "    }\n",
    "    return summary\n",
    "summary_stats = check_data_quality(transactions)\n",
    "summary_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "e3703039",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_clean_transactions_csv(df: pd.DataFrame, export_dir: str, filename: str):\n",
    "    os.makedirs(export_dir, exist_ok=True)\n",
    "    path = os.path.join(export_dir, filename)\n",
    "    df.to_csv(path, index=False)\n",
    "    print(f\"Cleaned transactions CSV saved to: {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "6c42aa6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_ohe_csv(ohe_df: pd.DataFrame, export_dir: str, filename: str):\n",
    "    os.makedirs(export_dir, exist_ok=True)\n",
    "    path = os.path.join(export_dir, filename)\n",
    "    ohe_df.to_csv(path, index=False)\n",
    "    print(f\"One-hot encoded CSV saved to: {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "8a415773",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_summary_csv(summary: Dict[str, Any], export_dir: str, filename: str):\n",
    "    \"\"\"Save a human-readable summary DataFrame built from the summary dict.\"\"\"\n",
    "    os.makedirs(export_dir, exist_ok=True)\n",
    "    # Build a flat summary dataframe\n",
    "    flat = {\n",
    "        \"num_transactions\": summary.get(\"num_transactions\", 0),\n",
    "        \"avg_tx_length\": summary.get(\"avg_tx_length\", 0),\n",
    "        \"min_tx_length\": summary.get(\"min_tx_length\", 0),\n",
    "        \"max_tx_length\": summary.get(\"max_tx_length\", 0),\n",
    "        \"num_unique_items\": summary.get(\"num_unique_items\", 0)\n",
    "    }\n",
    "    df_flat = pd.DataFrame([flat])\n",
    "    # Top items (if present) as separate columns concatenated\n",
    "    top_items = summary.get(\"top_20_items\", [])\n",
    "    if top_items:\n",
    "        df_top = pd.DataFrame(top_items, columns=[\"item\", \"count\"])\n",
    "        df_summary = pd.concat([df_flat, df_top], axis=1)\n",
    "    else:\n",
    "        df_summary = df_flat\n",
    "    path = os.path.join(export_dir, filename)\n",
    "    df_summary.to_csv(path, index=False)\n",
    "    print(f\"Summary CSV saved to: {path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "923ebb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat = {\n",
    "        \"num_transactions\": summary_stats.get(\"num_transactions\", 0),\n",
    "        \"avg_tx_length\": summary_stats.get(\"avg_tx_length\", 0),\n",
    "        \"min_tx_length\": summary_stats.get(\"min_tx_length\", 0),\n",
    "        \"max_tx_length\": summary_stats.get(\"max_tx_length\", 0),\n",
    "        \"num_unique_items\": summary_stats.get(\"num_unique_items\", 0)\n",
    "    }\n",
    "df_flat = pd.DataFrame([flat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "0555541f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_transactions</th>\n",
       "      <th>avg_tx_length</th>\n",
       "      <th>min_tx_length</th>\n",
       "      <th>max_tx_length</th>\n",
       "      <th>num_unique_items</th>\n",
       "      <th>item</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>milk</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bread</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>eggs</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>juice</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>soap</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>potatoes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>coffee</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>onions</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_transactions  avg_tx_length  min_tx_length  max_tx_length  \\\n",
       "0               3.0       2.666667            2.0            3.0   \n",
       "1               NaN            NaN            NaN            NaN   \n",
       "2               NaN            NaN            NaN            NaN   \n",
       "3               NaN            NaN            NaN            NaN   \n",
       "4               NaN            NaN            NaN            NaN   \n",
       "5               NaN            NaN            NaN            NaN   \n",
       "6               NaN            NaN            NaN            NaN   \n",
       "7               NaN            NaN            NaN            NaN   \n",
       "\n",
       "   num_unique_items      item  count  \n",
       "0               8.0      milk      1  \n",
       "1               NaN     bread      1  \n",
       "2               NaN      eggs      1  \n",
       "3               NaN     juice      1  \n",
       "4               NaN      soap      1  \n",
       "5               NaN  potatoes      1  \n",
       "6               NaN    coffee      1  \n",
       "7               NaN    onions      1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build and display a readable summary DataFrame if `summary_stats` exists\n",
    "try:\n",
    "    flat = {\n",
    "        \"num_transactions\": summary_stats.get(\"num_transactions\", 0),\n",
    "        \"avg_tx_length\": summary_stats.get(\"avg_tx_length\", 0),\n",
    "        \"min_tx_length\": summary_stats.get(\"min_tx_length\", 0),\n",
    "        \"max_tx_length\": summary_stats.get(\"max_tx_length\", 0),\n",
    "        \"num_unique_items\": summary_stats.get(\"num_unique_items\", 0)\n",
    "    }\n",
    "    df_flat = pd.DataFrame([flat])\n",
    "    top_items = summary_stats.get(\"top_20_items\", [])\n",
    "    if top_items:\n",
    "        df_top = pd.DataFrame(top_items, columns=[\"item\", \"count\"])\n",
    "        df_summary = pd.concat([df_flat, df_top], axis=1)\n",
    "    else:\n",
    "        df_summary = df_flat\n",
    "    display(df_summary)\n",
    "except NameError:\n",
    "    print(\"summary_stats is not defined. Run the preprocessing pipeline first.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3f0d3a",
   "metadata": {},
   "source": [
    "`num_transactions`\tTotal number of transactions in your dataset. Only the first row has this value because the code repeated the summary stats for every top item. Here, 5000 transactions.\n",
    "\n",
    "`avg_tx_length`\tAverage number of items per transaction. Here 4.4904 items on average.\n",
    "\n",
    "`min_tx_length`\tSmallest transaction length (number of items). Here 2.0 items. \n",
    "`max_tx_length`\tLargest transaction length. Here 7.0 items. \n",
    "\n",
    "`num_unique_items`\tTotal number of unique items across all transactions. Here 30. \n",
    "\n",
    "`item`\t_Name of the item_. This comes from the top 20 most frequent items list. Repeats down the rows.\n",
    "count\tHow many times that item appears across all transactions. Example: \"soap\" occurs 788 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "ba4db49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_pipeline(LOAD_PATH: Optional[str] = None) -> Tuple[pd.DataFrame, pd.DataFrame, Dict[str, Any]]:\n",
    "    df_original = pd.read_csv(LOAD_PATH) \n",
    "    transactions_raw = df_original.iloc[:, -1].apply(lambda x: str(x).split(\",\")).tolist()\n",
    "\n",
    "    cleaned_tx = clean_transactions(transactions_raw) \n",
    "    sorted_tx = sort_items_in_transactions(cleaned_tx)\n",
    "\n",
    "    df_cleaned = pd.DataFrame({\"cleaned_items\": [\"; \".join(tx) for tx in sorted_tx]})\n",
    "    \n",
    "    ohe_df = one_hot_encode_transactions(sorted_tx)\n",
    "    summary_stats = check_data_quality(sorted_tx)\n",
    "\n",
    "    return df_cleaned, ohe_df, summary_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "b35d55a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned transactions CSV saved to: preprocessed_outputs\\clean_transactions.csv\n",
      "One-hot encoded CSV saved to: preprocessed_outputs\\one_hot_transactions.csv\n",
      "Summary CSV saved to: preprocessed_outputs\\preprocessing_summary.csv\n"
     ]
    }
   ],
   "source": [
    "# Ensure preprocessing has been executed before saving outputs\n",
    "try:\n",
    "    df_cleaned, ohe_df, summary_stats  # check if already present\n",
    "except NameError:\n",
    "    df_cleaned, ohe_df, summary_stats = preprocess_pipeline(LOAD_PATH)\n",
    "\n",
    "save_clean_transactions_csv(df_cleaned, EXPORT_DIR, CLEAN_CSV_NAME)\n",
    "save_ohe_csv(ohe_df, EXPORT_DIR, OHE_CSV_NAME)\n",
    "save_summary_csv(summary_stats, EXPORT_DIR, SUMMARY_CSV_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "5ac6c3ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of transactions: 5000\n",
      "Unique items (sample): ['apples', 'bananas', 'beef', 'bread', 'butter', 'carrots', 'cereal', 'cheese', 'chicken', 'coffee']\n",
      "Top 10 items (item, count):\n",
      "[('soap', 788), ('bread', 787), ('salt', 786), ('toothpaste', 780), ('fish', 778), ('bananas', 776), ('shampoo', 773), ('tomatoes', 767), ('coffee', 762), ('flour', 761)]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    df_cleaned, ohe_df, summary_stats = preprocess_pipeline(LOAD_PATH)\n",
    "    \n",
    "    print(f\"Number of transactions: {summary_stats['num_transactions']}\")\n",
    "    print(f\"Unique items (sample): {summary_stats['unique_items_sample'][:10]}\")\n",
    "    print(\"Top 10 items (item, count):\")\n",
    "    print(summary_stats[\"top_20_items\"][:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686646f8",
   "metadata": {},
   "source": [
    "**Apriori — generate & export frequent itemsets**\n",
    "\n",
    "This cell runs the Apriori algorithm on the one-hot-encoded transactions (`ohe_df`) and saves the top 10 frequent itemsets.\n",
    "\n",
    "- **Purpose:** find frequent item combinations using `mlxtend.frequent_patterns.apriori` with `min_support=0.05`.\n",
    "- **Input:** the one-hot encoded DataFrame `ohe_df`. If `ohe_df` is missing the cell will call `preprocess_pipeline(LOAD_PATH)` to create it.\n",
    "- **Output:** a `frequent_itemsets` DataFrame containing `itemsets` (frozensets) and `support` (fraction of transactions). The cell also creates `itemset_str` (readable string) for display and export.\n",
    "- **Display:** shows the top 10 itemsets sorted by `support` (readable `itemset_str` and `support`).\n",
    "- **Export:** writes `preprocessed_outputs/top10_itemsets.csv` with columns `itemset_str` and `support`.\n",
    "\n",
    "Notes / quick tips:\n",
    "- To restrict to itemsets of size ≥ 2: `frequent_itemsets[frequent_itemsets['itemsets'].apply(lambda s: len(s) >= 2)]`.\n",
    "- To generate association rules afterwards, use:\n",
    "  `from mlxtend.frequent_patterns import association_rules`\n",
    "  `rules = association_rules(frequent_itemsets, metric='confidence', min_threshold=0.6)` and filter by `lift` or `confidence` as needed.\n",
    "- If you change `LOAD_PATH`, ensure it points to the correct CSV (absolute path or `supermarket_transactions.csv` in the repo).\n",
    "\n",
    "Run instructions: execute preprocessing cells first (or run this cell alone — it will call the preprocessing pipeline automatically if `ohe_df` is not defined).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "611a9c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total frequent itemsets found: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\mlxtend\\frequent_patterns\\fpcommon.py:161: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemset_str</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>soap</td>\n",
       "      <td>0.1576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bread</td>\n",
       "      <td>0.1574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>salt</td>\n",
       "      <td>0.1572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>toothpaste</td>\n",
       "      <td>0.1560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fish</td>\n",
       "      <td>0.1556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bananas</td>\n",
       "      <td>0.1552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>shampoo</td>\n",
       "      <td>0.1546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tomatoes</td>\n",
       "      <td>0.1534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>coffee</td>\n",
       "      <td>0.1524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>flour</td>\n",
       "      <td>0.1522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  itemset_str  support\n",
       "0        soap   0.1576\n",
       "1       bread   0.1574\n",
       "2        salt   0.1572\n",
       "3  toothpaste   0.1560\n",
       "4        fish   0.1556\n",
       "5     bananas   0.1552\n",
       "6     shampoo   0.1546\n",
       "7    tomatoes   0.1534\n",
       "8      coffee   0.1524\n",
       "9       flour   0.1522"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 itemsets exported to: preprocessed_outputs\\top10_itemsets.csv\n"
     ]
    }
   ],
   "source": [
    "# Apriori: generate frequent itemsets and export top 10\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "import os\n",
    "\n",
    "# Ensure the preprocessing pipeline has been run and `ohe_df` exists.\n",
    "try:\n",
    "    ohe_df  # noqa: F821\n",
    "except NameError:\n",
    "    df_cleaned, ohe_df, summary_stats = preprocess_pipeline(LOAD_PATH)\n",
    "\n",
    "# Run apriori to get frequent itemsets with minimum support 0.05\n",
    "frequent_itemsets = apriori(ohe_df, min_support=0.05, use_colnames=True)\n",
    "\n",
    "# Add readable itemset string for display/export\n",
    "frequent_itemsets['itemset_str'] = frequent_itemsets['itemsets'].apply(lambda s: ', '.join(sorted(list(s))))\n",
    "\n",
    "# Sort by support and select top 10\n",
    "frequent_itemsets_sorted = frequent_itemsets.sort_values(by='support', ascending=False).reset_index(drop=True)\n",
    "top10_itemsets = frequent_itemsets_sorted.head(10)\n",
    "\n",
    "# Display top 10 itemsets (itemset string and support)\n",
    "print(f\"Total frequent itemsets found: {len(frequent_itemsets)}\")\n",
    "display(top10_itemsets[['itemset_str', 'support']])\n",
    "\n",
    "# Export the top 10 itemsets to CSV\n",
    "os.makedirs(EXPORT_DIR, exist_ok=True)\n",
    "export_path = os.path.join(EXPORT_DIR, 'top10_itemsets.csv')\n",
    "top10_itemsets[['itemset_str', 'support']].to_csv(export_path, index=False)\n",
    "print(f\"Top 10 itemsets exported to: {export_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
